{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "逻辑回归定义\n",
    "分类为1的概率 P(x = 1) = exp{wx} / 1 + exp{wx}，\n",
    "相应的P(x = 0) = 1 / 1 + exp{wx}。\n",
    "\n",
    "令P(x = 1) = f(z) = exp{z} / 1 + exp{z}，其中z = wx，对P(z)求导，\n",
    "可以得到dP/dz = P(z) * (1 - P(z))\n",
    "\n",
    "对于单个sample的损失函数： \n",
    "loss = y * (1 - lnP(z)) + (1 - y) * lnP(z)，\n",
    "当y = 1时，loss = (1 - P(z), 若P(z) -> 1，loss -> 0；若P(z) -> 0，loss -> 无穷大\n",
    "y = 0时，loss = (1 - y) * P(z)，如果若P(z) -> 0，loss -> 0；若P(z) -> 1，loss -> 无穷大\n",
    "\n",
    "loss求导\n",
    "loss对某个w求导，有 d(loss)/d(wi) = (y - f(z))xi (这里需要做loss的导数推导，并利用到上一步的等式)\n",
    "这个推导我依然还是有问题，需要再仔细看看。\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import math \n",
    "\n",
    "cancer = datasets.load_breast_cancer() \n",
    "\n",
    "df_X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df_y = pd.DataFrame(cancer.target, columns=[\"target\"])\n",
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "特征要注意归一化\n",
    "\"\"\"\n",
    "class LogisticRegression(object):\n",
    "    def __init__(self, iteration, feature_num):\n",
    "        self.lr = 0.0001\n",
    "        self.max_iteration = iteration\n",
    "        # wx + b\n",
    "        self.w = np.zeros(feature_num + 1)\n",
    "    \n",
    "    def train(self, features, lables):\n",
    "        cur_iter = 0\n",
    "        while True:\n",
    "            if cur_iter > self.max_iteration:\n",
    "                break\n",
    "        # 每次拿出一个sample更新\n",
    "        index = random.randint(0, len(labels) - 1)\n",
    "        cur_features = list(features[index])\n",
    "        # 加入bias\n",
    "        cur_features.append(1.0)\n",
    "        y = labels[index]\n",
    "        x = np.array(cur_features)\n",
    "        wx = np.dot(self.w, x)\n",
    "        exp_wx = math.exp(wx)\n",
    "        yhat = exp_wx / (1 + exp_wx)\n",
    "        for i in xrange(len(self.w)):\n",
    "            # 每一个sample可以用来更新所有的w值\n",
    "            \"\"\"\n",
    "            如果y = 1, 而yhat -> 0，即f(z) -> 0，说明预测有误，为了提高预测概率，要提高f(z)的值。\n",
    "            P(x = 1) = exp{wx} / 1 + exp{wx} = 1 - 1 / (1 + exp(wx))，要让P(X = 1)提高，下一轮需要提高wx的值。\n",
    "            如果x[i] > 0，则+号使得w[i]增加了，则下一轮的wx增加，P(x = 1)提高，不论w[x]以前是正负，都是这个结论。\n",
    "            如果x[i] < 0，则+号使得w[i]减小了，w[i]*x[i]减小了，不论w[x]以前是正负，都是这个结论。\n",
    "            综上，+号更新是正确的。同理，可以假设y = 0来推导，应该同样成立。\n",
    "            \"\"\"\n",
    "            self.w[i] += self.lr * (y - yhat) * x[i]\n",
    "        return \n",
    "    \n",
    "    def predict_single(self, x):\n",
    "        try:\n",
    "            wx = np.dot(self.w, x)\n",
    "            exp_wx = math.exp(wx)\n",
    "            predict_1 = exp_wx / (1 + exp_wx)\n",
    "            predict_0 = 1 / (1 + exp_wx)\n",
    "            if predict1 > predict0:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        except OverflowError:\n",
    "            print x\n",
    "            print self.w\n",
    "    \n",
    "    def predict_batch(self, features):\n",
    "        labels = []\n",
    "        for feature in features:\n",
    "            cur_features = list(feature)\n",
    "            cur_features.append(1.0)\n",
    "            x = np.array(cur_features)\n",
    "            labels.append(self.predict_single(x))\n",
    "        return labels\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
