{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "see https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb.\n",
    "使用了attention机制的法语-英语的翻译。\n",
    "教程中包括了还比较多的错误，现在已经修复。\n",
    "提高性能的办法：\n",
    "    1. 增加epochs。\n",
    "    2. 增加训练集。\n",
    "    3. 加大超参。\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../common/\")\n",
    "import english2franch_helper\n",
    "import time_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "将word变成encoder/decoder的输入\n",
    "\"\"\"\n",
    "def indexes_from_sentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def variable_from_sentence(lang, sentence):\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    var = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    return var\n",
    "\n",
    "\n",
    "def variables_from_pair(pair):\n",
    "    input_variable = variable_from_sentence(input_lang, pair[0])\n",
    "    target_variable = variable_from_sentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \"\"\"\n",
    "        num_embeddings - 嵌入字典的大小\n",
    "        embedding_dim - 每个嵌入向量的大小\n",
    "        \"\"\"\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        \"\"\"\n",
    "         input_size – 期望的输入x的特征值的维度 \n",
    "         hidden_size – 隐状态的维度 \n",
    "         num_layers – RNN的层数\n",
    "        \"\"\"\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "\n",
    "    def forward(self, word_inputs, hidden):\n",
    "        \"\"\"\n",
    "        :param word_inputs: 是一个(seq, 1)的序列\n",
    "        :param hidden:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        seq_len = len(word_inputs)\n",
    "        \"\"\"\n",
    "        nn.embedding的输入 - LongTensor (N, W), \n",
    "            N - mini-batch的sample个数, \n",
    "            W - 序列长度\n",
    "        一维tensor也可以接受？实际上用的时候更灵活，只要按照自己的语义来做传入就行，例如像本例，其实是传入的是(seq, 1)，reshape的时候\n",
    "        将输入变成了GRU要求的形式。\n",
    "        nn.embedding的输出 - (N, W, embedding_dim)\n",
    "            N,W - 跟上面的一样\n",
    "            embedding_dim - embedding的维度\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(word_inputs)\n",
    "        # 变成GRU要求的形式。\n",
    "        embedded_reshape = embedded.view(seq_len, 1, -1)\n",
    "        \"\"\"\n",
    "        nn.GRU的输入 - input, h_0\n",
    "            input(seq_len, batch, embedding_dim)\n",
    "            h_0(num_layers * num_directions, batch, hidden_size) - 隐含状态，一般来说num_layers=1，num_directions=2是bi。\n",
    "        nn.GRU的输出 - output, h_n\n",
    "            output(seq_len, batch, hidden_size * num_directions) - 这个输出有点搞不懂\n",
    "            h_n(num_layers * num_directions, batch, hidden_size) - 与输入相同\n",
    "        \"\"\"\n",
    "        # 注意，对于encoder端，我们一次性将encoder的输入一次forward处理了。结果返回了seq个output和最后的hidden state。\n",
    "        output, hidden = self.gru(embedded_reshape, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # encoder的初始hidden state为全0\n",
    "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        return hidden\n",
    "\n",
    "\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size, max_length=MAX_LENGTH):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.other = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = len(encoder_outputs)\n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(seq_len))\n",
    "        # 计算相关性，有好几种计算方法，可以认为是每个word对应一个权重\n",
    "        for i in range(seq_len):\n",
    "            attn_energies[i] = self.score(hidden, encoder_outputs[i])\n",
    "        # resize to 1 x 1 x seq_len\n",
    "        return F.softmax(attn_energies, dim=0).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    def score(self, hidden, encoder_output):\n",
    "        if self.method == 'dot':\n",
    "            # 我估计这里也得像'general'那样改\n",
    "            energy = hidden.dot(encoder_output)\n",
    "            return energy\n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = hidden.view(-1).dot(energy.view(-1))\n",
    "            return energy\n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = self.other.dot(energy)\n",
    "            return energy\n",
    "\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \"\"\"\n",
    "         output_size – 词表大小 \n",
    "         hidden_size – embedding的大小 \n",
    "        \"\"\"\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        \"\"\"\n",
    "         期望的输入x的特征值的维度 \n",
    "         隐状态的维度 \n",
    "         RNN的层数\n",
    "         为什么是hidden_size * 2呢，因为context也作为输入 - 待删除\n",
    "        \"\"\"\n",
    "        # self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "        # Choose attention model\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    # 实现的是Luong Attention的global版本\n",
    "    # https://blog.floydhub.com/attention-mechanism/\n",
    "    # 步骤是：\n",
    "    # 1. 收集encoder的所有输出，作为context向量计算的源头之一。\n",
    "    # 2. 前面decoder的hidden和输出传入一个decoder的RNN组件，为当前的time step产生一个新的output/hidden\n",
    "    # 3. 计算Alignment Scores。使用新的output和encoder的所有output算分。有好几种方式。\n",
    "    # 4. Softmax分数。\n",
    "    # 5. 使用encoder的输出和计算出来的分数计算context向量。\n",
    "    # 6. concat context向量和在第二步中生成的output作为输入传如到一个新的DNN并得到输出。\n",
    "    # 7. 返回重复过程，直到最大长度。\n",
    "    # 上述整个描述复合整个forward函数，除了使用了last_context，把整个去掉看看。\n",
    "    def forward(self, word_input, last_context, last_hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        对于decoder，我们是一个单词一个单词的处理的，因为要加入attention\n",
    "        感觉这个实现也不完全是按照Luong Attention的global方式做的？\n",
    "        layer=1的情况\n",
    "        :param word_input: 2维的，每次一个单词的int表示，例如<SOS_token>是[[0]]\n",
    "        :param last_context: 2维，(1, hidden_size)\n",
    "        :param last_hidden: 3维，(1, 1, hidden_size)\n",
    "        :param encoder_outputs: 3维, (seq_len, 1, hidden_state)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 获取输入的embedding\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S= 1 x B x N\n",
    "        # 组合embedding input和last_context向量，这里的rnn_input为什么用到了last_context? - 拿掉last_context看看\n",
    "        # rnn_input = torch.cat((word_embedded, last_context.unsqueeze(0)), 2)\n",
    "        rnn_input = word_embedded\n",
    "        rnn_output, hidden = self.gru(rnn_input, last_hidden)\n",
    "        \"\"\"\n",
    "        计算attention的分数。先拿到了rnn_output，然后计算它与前面的encoder_output的相关性。\n",
    "        调用的是Attn的forward()函数\n",
    "        \"\"\"\n",
    "        attn_weights = self.attn(rnn_output.squeeze(0), encoder_outputs)\n",
    "        # 这个bmm是做了什么啊？- 就是在计算context向量的矩阵运算方法\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        # Final output layer (next word prediction) using the RNN hidden state and context vector\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "        output = F.log_softmax(self.out(torch.cat((rnn_output, context), 1)), dim=1)\n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, context, hidden, attn_weights\n",
    "\n",
    "\n",
    "def train_single(input_variable, target_variable, encoder, decoder,\n",
    "                 encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    为了训练，我们将输入的句子一个个word进入，并且保存每个输出和最近的hidden state，decoder将encoder的最后一个hidden  state作为初始的hidden state，<SOS>token作为第一个输入。\n",
    "    交替使用teacher forcing和decoder本身预测的输出作为下一个输入。\n",
    "    \"\"\"\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "    \"\"\"\n",
    "    encoder的初始hidden state是[0, 0, 0...]\n",
    "    encoder_outputs 作为decoder计算attention\n",
    "    返回的encoder_hidden作为decoder的初始hidden state，这个hidden state是3维的 \n",
    "    \"\"\"\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    # SOS_token作为第一个输入\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "    # last hidden state from encoder to start decoder\n",
    "    decoder_hidden = encoder_hidden\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Use the ground-truth target as the next input\n",
    "        for di in range(target_length):\n",
    "            # 调用AttnDecoderRNN的forward()函数\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = \\\n",
    "                decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di] # Next target is next input\n",
    "    else:\n",
    "        # Without teacher forcing: use network's own prediction as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = \\\n",
    "                decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            # 使用概率最高的decoder的输出作为下一步的输入\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]])) # Chosen word is next input\n",
    "            # Stop at end of sentence (not necessary when using known targets)\n",
    "            if ni == EOS_token: break\n",
    "    # 这里说明整个句子被统一计算loss\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    return loss / target_length\n",
    "\n",
    "\n",
    "print(\"#0 read data\")\n",
    "input_lang, output_lang, pairs = english2franch_helper.prepare_translation_raw_data_for_task()\n",
    "print(random.choice(pairs))\n",
    "\n",
    "print(\"#1 define parameters\")\n",
    "attn_model = 'general'\n",
    "hidden_size = 128\n",
    "# n_layers = 2\n",
    "n_layers = 2\n",
    "dropout_p = 0.05\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers)\n",
    "decoder = AttnDecoderRNN(attn_model, hidden_size, output_lang.n_words, n_layers, dropout_p=dropout_p)\n",
    "\n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "n_epochs = 20000\n",
    "plot_every = 200\n",
    "print_every = 500\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0\n",
    "plot_loss_total = 0\n",
    "\n",
    "print(\"#2 start to train\")\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    training_pair = variables_from_pair(random.choice(pairs))\n",
    "    # input_variable, target_variable是二维的\n",
    "    input_variable = training_pair[0]\n",
    "    target_variable = training_pair[1]\n",
    "    loss = train_single(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "    if epoch == 0: continue\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = '%s (%d %d%%) %.4f' % (time_utils.time_since(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg)\n",
    "        print(print_summary)\n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0\n",
    "\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "\n",
    "show_plot(plot_losses)\n",
    "\n",
    "\n",
    "def evaluate(sentence, max_length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    跟train_single的逻辑是类似的。\n",
    "    \"\"\"\n",
    "    input_variable = variable_from_sentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]])) # SOS\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_context, decoder_hidden, decoder_attention = \\\n",
    "            decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "        # 记录了当前这个di对于encoder outputs也可以说是原input sequence的attention weight。\n",
    "        decoder_attentions[di, :decoder_attention.size(2)] += \\\n",
    "            decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi.numpy()[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "        # Next input is chosen word\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "    return decoded_words, decoder_attentions[:di+1, :len(encoder_outputs)]\n",
    "\n",
    "\n",
    "def evaluate_randomly():\n",
    "    pair = random.choice(pairs)\n",
    "    output_words, decoder_attn = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    print('>', pair[0])\n",
    "    print('=', pair[1])\n",
    "    print('<', output_sentence)\n",
    "    print('')\n",
    "\n",
    "\n",
    "print(\"#3 random sample\")\n",
    "evaluate_randomly()\n",
    "\n",
    "\n",
    "def show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def evaluate_and_show_attention(input_sentence, target_sentence):\n",
    "    output_words, attentions = evaluate(input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('target=', target_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    show_attention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "print(\"#4 show attention\")\n",
    "pair = random.choice(pairs)\n",
    "evaluate_and_show_attention(pair[0], pair[1])\n",
    "\n",
    "pair = random.choice(pairs)\n",
    "evaluate_and_show_attention(pair[0], pair[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
