{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "\"\"\"\n",
    "比较numpy和torch tensor操作\n",
    "其他的math运算见http://pytorch.org/docs/torch.html#math-operations\n",
    "也可以https://pytorch.org/docs/stable/torch.html来查找定义\n",
    "需要熟悉其中的一些操作，这样才能自己实现一些东西\n",
    "一些基本操作都要放在这个文件\n",
    "\"\"\"\n",
    "\n",
    "# numpy数据和torch数据的转换\n",
    "np_data = np.arange(6).reshape((2, 3))\n",
    "torch_data = torch.from_numpy(np_data)\n",
    "tensor2array = torch_data.numpy()\n",
    "print(\n",
    "    '\\nnumpy array:\\n', np_data,          # [[0 1 2], [3 4 5]]\n",
    "    '\\ntorch tensor:\\n', torch_data,      #  0  1  2 \\n 3  4  5    [torch.LongTensor of size 2x3]\n",
    "    '\\ntensor to numpy:\\n', tensor2array, # [[0 1 2], [3 4 5]]\n",
    ")\n",
    "\n",
    "# 转换后的内存共享\n",
    "a = np.array([1, 2, 3])\n",
    "v = torch.from_numpy(a)         # Convert a numpy array to a Tensor\n",
    "b = v.numpy()                   # Tensor to numpy\n",
    "b[1] = -1                       # Numpy and Tensor share the same memory\n",
    "assert(a[1] == b[1])            # Change Numpy will also change the Tensor\n",
    "print(a)\n",
    "print(b)\n",
    "print(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tensor初始化\n",
    "\"\"\"\n",
    "print(\"\\nsimple initilization\")\n",
    "v1 = torch.Tensor(2, 3)          # An un-initialized torch.FloatTensor of size 2x3\n",
    "v2 = torch.Tensor([[1,2],[4,5]]) # A Tensor initialized with a specific array\n",
    "v3 = torch.LongTensor([1,2,3])   # A Tensor of type Long\n",
    "print(v1)\n",
    "print(v2)\n",
    "print(v3)\n",
    "\n",
    "print(\"\\nset mannal seed, stable result\")\n",
    "# 使用这个可以得到一样的v1,v2,v3\n",
    "torch.manual_seed(1)\n",
    "v1 = torch.rand(2, 3)            # Initialize with random number (uniform distribution)\n",
    "v2 = torch.randn(2, 3)           # With normal distribution (SD=1, mean=0)\n",
    "v3 = torch.randperm(4)\n",
    "print(v1)\n",
    "print(v2)\n",
    "print(v3)\n",
    "\n",
    "print(\"\\nfrom np array\")\n",
    "np_data = np.arange(6).reshape((2, 3))\n",
    "tensor = torch.from_numpy(np_data)\n",
    "print(tensor)\n",
    "\n",
    "print(\"\\nfrom normal array\")\n",
    "array = [-1, -2, 1, 2]\n",
    "tensor = torch.FloatTensor(array) \n",
    "print(tensor)\n",
    "\n",
    "print(\"\\nnp array like style\")\n",
    "v1 = torch.arange(5)             # similar to range(5) but creating a Tensor\n",
    "v2 = torch.arange(0, 5, step=1)  # Size 5. Similar to range(0, 5, 1)\n",
    "print(v1)\n",
    "print(v2)\n",
    "\n",
    "print(\"\\nfill 0 and 1\")\n",
    "v1 = torch.ones((2,3)) \n",
    "v2 = torch.zeros((2,3))\n",
    "print(v1)\n",
    "print(v2)\n",
    "\n",
    "print(\"\\nimportant - always used to init weight\")\n",
    "v1 = torch.Tensor(2, 2).uniform_(0, 1)\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "单个tensor的操作\n",
    "\"\"\"\n",
    "# reshape\n",
    "array = [-1, -2, 1, 2]\n",
    "tensor = torch.FloatTensor(array)  # 32-bit floating point\n",
    "tensor_reshape = tensor.view(2,2)\n",
    "print(\"\\ntensor\")\n",
    "print(tensor)\n",
    "print(\"\\ntensor_reshape\")\n",
    "print(tensor_reshape)\n",
    "\n",
    "\n",
    "print(\"\\n1d index and slicing\")\n",
    "# 1d index and slicing\n",
    "print(tensor[1])\n",
    "print(tensor[-1])\n",
    "print(tensor[1:])\n",
    "# 2d index index and slicing\n",
    "tensor_2d = torch.Tensor([[1,2,3],[4,5,6], [7,8,9]]) \n",
    "print(tensor_2d)\n",
    "print(\"\\n2d index and slicing\")\n",
    "print(tensor_2d[0])\n",
    "# 左闭合右开，如果两边相等，则不取\n",
    "print(tensor_2d[0:1, :])\n",
    "print(tensor_2d[1:2, :])\n",
    "print(tensor_2d[2:3, :])\n",
    "print(tensor_2d[:, 0:1])\n",
    "print(tensor_2d[:, 1:2])\n",
    "print(tensor_2d[:, 2:3])\n",
    "# 最右下角\n",
    "print(tensor_2d[1:3, 1:3])\n",
    "\n",
    "# abs\n",
    "data = [-1, -2, 1, 2]\n",
    "tensor = torch.FloatTensor(data)  # 32-bit floating point\n",
    "print(\n",
    "    '\\nabs',\n",
    "    '\\nnumpy: \\n', np.abs(data),          # [1 2 1 2]\n",
    "    '\\ntorch: \\n', torch.abs(tensor)      # [1 2 1 2]\n",
    ")\n",
    "data_2d = np.array([-1, -2, 1, 2]).reshape((2,2))\n",
    "tensor_2d = torch.FloatTensor(data_2d)\n",
    "print(\n",
    "    '\\n2d abs',\n",
    "    '\\nnumpy: \\n', np.abs(data_2d),         \n",
    "    '\\ntorch: \\n', torch.abs(tensor_2d)     \n",
    ")\n",
    "\n",
    "# mean\n",
    "data = [-1, -2, 1, 2]\n",
    "tensor = torch.FloatTensor(data)  # 32-bit floating point\n",
    "print(\n",
    "    '\\nmean',\n",
    "    '\\nnumpy: \\n', np.mean(data),         # 0.0\n",
    "    '\\ntorch: \\n', torch.mean(tensor)     # 0.0\n",
    ")\n",
    "\n",
    "data_2d = np.array([-1, -2, 1, 2]).reshape((2,2))\n",
    "tensor_2d = torch.FloatTensor(data_2d)\n",
    "print(\n",
    "    '\\n2d mean',\n",
    "    '\\nnumpy: \\n', np.mean(data_2d),         # 0.0\n",
    "    '\\ntorch: \\n', torch.mean(tensor_2d)     # 0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "多个tensor的操作\n",
    "\"\"\"\n",
    "# add, 基于元素的\n",
    "print(\"\\nadd\")\n",
    "x1 = torch.Tensor([[1,2],[4,5]])  \n",
    "x2 = torch.Tensor([[1,2],[4,5]]) \n",
    "y1 = x1 + x2\n",
    "y2 = torch.add(x1, x2)\n",
    "y3 = x1.add(x2)\n",
    "print(y1)\n",
    "print(y2)\n",
    "print(y3)\n",
    "\n",
    "# *，基于元素的\n",
    "print(\"\\ntensor *\")\n",
    "tensor_2d = torch.Tensor([[1,2],[4,5]]) \n",
    "print(tensor_2d*tensor_2d)\n",
    "\n",
    "\n",
    "# matrix multiplication\n",
    "data = [[1,2], [3,4]]\n",
    "tensor = torch.FloatTensor(data)  # 32-bit floating point\n",
    "print(\n",
    "    '\\nmatrix multiplication (matmul)',\n",
    "    '\\nnumpy: \\n', np.matmul(data, data),     # [[7, 10], [15, 22]]\n",
    "    '\\ntorch: \\n', torch.mm(tensor, tensor)   # [[7, 10], [15, 22]]\n",
    ")\n",
    "\n",
    "# dot，注意numpy中的dot操作其实跟矩阵乘法类似，但是torch的tensor操作是不一样的。\n",
    "data = [[1,2], [3,4]]\n",
    "tensor = torch.FloatTensor(data)  # 32-bit floating point\n",
    "data = np.array(data)\n",
    "tensor_flatten = torch.flatten(tensor)\n",
    "print(\n",
    "    '\\ndot',\n",
    "    '\\nnumpy: \\n', data.dot(data),     # [[7, 10], [15, 22]]\n",
    "    #'\\ntorch: \\n', torch.dot(tensor, tensor)   # 现在二维的已经不支持直接这样做了。\n",
    "    '\\ntorch: \\n', torch.dot(tensor_flatten, tensor_flatten)  # 30\n",
    ")\n",
    "\n",
    "# cat\n",
    "\"\"\"\n",
    "对于2d，可以简单的认为\n",
    "dim0的cat是将添加行+重新组织矩阵，dim1的cat是添加列+重新组织矩阵\n",
    "\"\"\"\n",
    "tensor_2d = torch.Tensor([[1,2],[4,5]]) \n",
    "dim0_cat = torch.cat((tensor_2d, tensor_2d, tensor_2d), 0)\n",
    "print(\"\\ndim 0 cat\")\n",
    "print(dim0_cat)\n",
    "dim1_cat = torch.cat((tensor_2d, tensor_2d, tensor_2d), 1)\n",
    "print(\"\\ndim 1 cat\")\n",
    "print(dim1_cat)\n",
    "\n",
    "# 元素级别的比较\n",
    "tensor_2d_1 = torch.Tensor([[1,2],[4,5],[7,8]]) \n",
    "tensor_2d_2 = torch.Tensor([[1,2],[4,5],[7,9]]) \n",
    "print(\"\\nelement equal\")\n",
    "print(torch.eq(tensor_2d_1,tensor_2d_2))\n",
    "\n",
    "\"\"\"\n",
    "reduce操作\n",
    "\"\"\"\n",
    "tensor_2d = torch.Tensor([[1,2],[4,5],[7,8]]) \n",
    "print(\"\\norigin tensor\")\n",
    "print(tensor_2d)\n",
    "print(\"\\ndim 0 reduce\")\n",
    "print(torch.sum(tensor_2d, dim=0))\n",
    "print(\"\\ndim 1 reduce\")\n",
    "print(torch.sum(tensor_2d, dim=1))\n",
    "\n",
    "# split\n",
    "tensor_2d = torch.Tensor([[1,2],[4,5],[7,8]]) \n",
    "print(\"\\norigin tensor\")\n",
    "print(tensor_2d)\n",
    "print(\"\\nchunk\")\n",
    "print(torch.chunk(tensor_2d, 3))\n",
    "print(\"\\nsplit\")\n",
    "print(torch.split(tensor_2d, 2))\n",
    "\n",
    "# stack添加了新维度\n",
    "r = torch.stack((tensor_2d,tensor_2d))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_tensor\n",
    "print(torch.is_tensor(np_data))\n",
    "print(torch.is_tensor(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "重要 - 在定义自己的操作时经常用到的\n",
    "\"\"\"\n",
    "print(\"\\n1d dot\")\n",
    "r = torch.dot(torch.Tensor([4, 2]), torch.Tensor([3, 1])) # 14\n",
    "print(r)\n",
    "\n",
    "# 这个操作比较违反直觉\n",
    "print(\"\\n# Matrix X vector\")\n",
    "tensor1 = torch.Tensor([[1,2,3], [4,5,6]]) # 2*3\n",
    "tensor2 = torch.Tensor([0,1,0]) # 1*3\n",
    "print(torch.mv(tensor1, tensor2)) # 1*2, mv - matrix vector\n",
    "\n",
    "# 矩阵乘法\n",
    "print(\"\\nMatrix x Matrix\")\n",
    "tensor1 = torch.Tensor([[1,2,3], [4,5,6]])  # 2*3的矩阵\n",
    "tensor2 = torch.Tensor([[0],[1],[0]]) # 3*1矩阵\n",
    "print(torch.mm(tensor1, tensor2)) # 2*1的矩阵, mm - matrix matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorx = torch.Tensor([[1,2,3], [4,5,6]])\n",
    "flatten_tensor = torch.flatten(tensorx)\n",
    "print(flatten_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
