{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "比较numpy和torch tensor操作\n",
    "其他的math运算见http://pytorch.org/docs/torch.html#math-operations\n",
    "也可以https://pytorch.org/docs/stable/torch.html来查找定义\n",
    "需要熟悉其中的一些操作，这样才能自己实现一些东西\n",
    "一些基本操作都要放在这个文件\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dot \n",
      "numpy: \n",
      " [[ 7 10]\n",
      " [15 22]] \n",
      "torch: \n",
      " tensor(30.)\n",
      "\n",
      "dim 0 cat\n",
      "tensor([[1., 2.],\n",
      "        [4., 5.],\n",
      "        [1., 2.],\n",
      "        [4., 5.],\n",
      "        [1., 2.],\n",
      "        [4., 5.]])\n",
      "\n",
      "dim 1 cat\n",
      "tensor([[1., 2., 1., 2., 1., 2.],\n",
      "        [4., 5., 4., 5., 4., 5.]])\n",
      "\n",
      "origin tensor\n",
      "tensor([[1., 2.],\n",
      "        [4., 5.],\n",
      "        [7., 8.]])\n",
      "\n",
      "dim 0 reduce\n",
      "tensor([12., 15.])\n",
      "\n",
      "dim 1 reduce\n",
      "tensor([ 3.,  9., 15.])\n",
      "\n",
      "Matrix x Matrix\n",
      "tensor([[2.],\n",
      "        [5.]])\n",
      "tensor([[0.1000, 0.2000, 0.7000],\n",
      "        [0.4000, 0.5000, 0.1000]])\n",
      "torch.return_types.topk(\n",
      "values=tensor([[0.7000, 0.2000],\n",
      "        [0.5000, 0.4000]]),\n",
      "indices=tensor([[2, 1],\n",
      "        [1, 0]]))\n"
     ]
    }
   ],
   "source": [
    "# dot，注意numpy中的dot操作其实跟矩阵乘法类似，但是torch的tensor操作是不一样的。\n",
    "data = [[1,2], [3,4]]\n",
    "tensor = torch.FloatTensor(data)  # 32-bit floating point\n",
    "data = np.array(data)\n",
    "tensor_flatten = torch.flatten(tensor)\n",
    "print(\n",
    "    '\\ndot',\n",
    "    '\\nnumpy: \\n', data.dot(data),     # [[7, 10], [15, 22]]\n",
    "    #'\\ntorch: \\n', torch.dot(tensor, tensor)   # 现在二维的已经不支持直接这样做了。\n",
    "    '\\ntorch: \\n', torch.dot(tensor_flatten, tensor_flatten)  # 30\n",
    ")\n",
    "\n",
    "# cat\n",
    "\"\"\"\n",
    "对于2d，可以简单的认为\n",
    "dim0的cat是将添加行+重新组织矩阵，dim1的cat是添加列+重新组织矩阵\n",
    "\"\"\"\n",
    "tensor_2d = torch.Tensor([[1,2],[4,5]]) \n",
    "dim0_cat = torch.cat((tensor_2d, tensor_2d, tensor_2d), 0)\n",
    "print(\"\\ndim 0 cat\")\n",
    "print(dim0_cat)\n",
    "dim1_cat = torch.cat((tensor_2d, tensor_2d, tensor_2d), 1)\n",
    "print(\"\\ndim 1 cat\")\n",
    "print(dim1_cat)\n",
    "\n",
    "# reduce操作\n",
    "tensor_2d = torch.Tensor([[1,2],[4,5],[7,8]]) \n",
    "print(\"\\norigin tensor\")\n",
    "print(tensor_2d)\n",
    "print(\"\\ndim 0 reduce\")\n",
    "print(torch.sum(tensor_2d, dim=0))\n",
    "print(\"\\ndim 1 reduce\")\n",
    "print(torch.sum(tensor_2d, dim=1))\n",
    "\n",
    "# 矩阵乘法\n",
    "print(\"\\nMatrix x Matrix\")\n",
    "tensor1 = torch.Tensor([[1,2,3], [4,5,6]])  # 2*3的矩阵\n",
    "tensor2 = torch.Tensor([[0],[1],[0]]) # 3*1矩阵\n",
    "print(torch.mm(tensor1, tensor2)) # 2*1的矩阵, mm - matrix matrix\n",
    "\n",
    "# topk，这种输入一般是比较常见的，就是传出来多个预测概率数组，一次计算所有的。\n",
    "tensorx = torch.Tensor([[.1, .2, .7], [.4, .5, .1]])\n",
    "print(tensorx)\n",
    "# 这里跟我想的有点不一样，dim=1返回的才是想要的。\n",
    "print(torch.topk(tensorx, 2, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n1d index and slicing\")\n",
    "# 1d index and slicing\n",
    "print(tensor[1])\n",
    "print(tensor[-1])\n",
    "print(tensor[1:])\n",
    "# 2d index index and slicing\n",
    "tensor_2d = torch.Tensor([[1,2,3],[4,5,6], [7,8,9]]) \n",
    "print(tensor_2d)\n",
    "print(\"\\n2d index and slicing\")\n",
    "print(tensor_2d[0])\n",
    "# 左闭合右开，如果两边相等，则不取\n",
    "print(tensor_2d[0:1, :])\n",
    "print(tensor_2d[1:2, :])\n",
    "print(tensor_2d[2:3, :])\n",
    "print(tensor_2d[:, 0:1])\n",
    "print(tensor_2d[:, 1:2])\n",
    "print(tensor_2d[:, 2:3])\n",
    "# 最右下角\n",
    "print(tensor_2d[1:3, 1:3])\n",
    "\n",
    "# abs\n",
    "data = [-1, -2, 1, 2]\n",
    "tensor = torch.FloatTensor(data)  # 32-bit floating point\n",
    "print(\n",
    "    '\\nabs',\n",
    "    '\\nnumpy: \\n', np.abs(data),          # [1 2 1 2]\n",
    "    '\\ntorch: \\n', torch.abs(tensor)      # [1 2 1 2]\n",
    ")\n",
    "data_2d = np.array([-1, -2, 1, 2]).reshape((2,2))\n",
    "tensor_2d = torch.FloatTensor(data_2d)\n",
    "print(\n",
    "    '\\n2d abs',\n",
    "    '\\nnumpy: \\n', np.abs(data_2d),         \n",
    "    '\\ntorch: \\n', torch.abs(tensor_2d)     \n",
    ")\n",
    "\n",
    "# mean\n",
    "data = [-1, -2, 1, 2]\n",
    "tensor = torch.FloatTensor(data)  # 32-bit floating point\n",
    "print(\n",
    "    '\\nmean',\n",
    "    '\\nnumpy: \\n', np.mean(data),         # 0.0\n",
    "    '\\ntorch: \\n', torch.mean(tensor)     # 0.0\n",
    ")\n",
    "\n",
    "data_2d = np.array([-1, -2, 1, 2]).reshape((2,2))\n",
    "tensor_2d = torch.FloatTensor(data_2d)\n",
    "print(\n",
    "    '\\n2d mean',\n",
    "    '\\nnumpy: \\n', np.mean(data_2d),         # 0.0\n",
    "    '\\ntorch: \\n', torch.mean(tensor_2d)     # 0.0\n",
    ")\n",
    "\n",
    "# add, 基于元素的\n",
    "print(\"\\nadd\")\n",
    "x1 = torch.Tensor([[1,2],[4,5]])  \n",
    "x2 = torch.Tensor([[1,2],[4,5]]) \n",
    "y1 = x1 + x2\n",
    "y2 = torch.add(x1, x2)\n",
    "y3 = x1.add(x2)\n",
    "print(y1)\n",
    "print(y2)\n",
    "print(y3)\n",
    "\n",
    "# *，基于元素的\n",
    "print(\"\\ntensor *\")\n",
    "tensor_2d = torch.Tensor([[1,2],[4,5]]) \n",
    "print(tensor_2d * tensor_2d)\n",
    "\n",
    "# 元素级别的比较\n",
    "tensor_2d_1 = torch.Tensor([[1,2],[4,5],[7,8]]) \n",
    "tensor_2d_2 = torch.Tensor([[1,2],[4,5],[7,9]]) \n",
    "print(\"\\nelement equal\")\n",
    "print(torch.eq(tensor_2d_1,tensor_2d_2))\n",
    "\n",
    "\n",
    "# 这个操作比较违反直觉\n",
    "print(\"\\n# Matrix X vector\")\n",
    "tensor1 = torch.Tensor([[1,2,3], [4,5,6]]) # 2*3\n",
    "tensor2 = torch.Tensor([0,1,0]) # 1*3\n",
    "print(torch.mv(tensor1, tensor2)) # 1*2, mv - matrix vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_tensor\n",
    "print(torch.is_tensor(np_data))\n",
    "print(torch.is_tensor(tensor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
