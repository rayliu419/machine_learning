{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "textCNN做电影的情感分类任务\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./common/\")\n",
    "import english_preprocess\n",
    "import movie_review_helper\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(TextCNN, self).__init__()\n",
    "        print(args)\n",
    "        filter_num = args[\"filter_num\"]\n",
    "        filter_sizes = args[\"filter_sizes\"]\n",
    "        embedding_size = args[\"embedding_size\"]\n",
    "        drop_out_ratio = args[\"dropout\"]\n",
    "        class_num = args[\"class_num\"]\n",
    "        \"\"\"\n",
    "        Conv2d初始化参数\n",
    "            in_channels - NLP中是几种embedding方式\n",
    "            out_channels - filter的数目，多个filter可能是捕捉多种不同长度的模式\n",
    "            kernel_size - NLP中是ngram的(n, embedding_size)\n",
    "        \"\"\"\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.Conv2d(1, filter_num, (cur, embedding_size)) for cur in filter_sizes])\n",
    "        self.dropout = nn.Dropout(drop_out_ratio)\n",
    "        self.fc = nn.Linear(filter_num * len(filter_sizes), class_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = out.unsqueeze(1)\n",
    "        out = torch.cat([self.conv_and_pool(out, conv) for conv in self.convs], 1)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "    def conv_and_pool(self, x, conv):\n",
    "        \"\"\"\n",
    "        ngram的n=某个值的卷积和max_pool，一次计算多个sample，多个filter\n",
    "        Conv2d的输入解释：\n",
    "            N - batch的大小\n",
    "            C - 通道数量, 这里怎么理解？\n",
    "            H - 输入的高度\n",
    "            W - 输入的宽度\n",
    "        Conv2d的输出\n",
    "            N - batch大小，跟输入的是一样的。\n",
    "            C - 根据例子来看，是跟Conv2d初始化的filter_num是一样的。\n",
    "            H - 高度，在textCNN中其实就是filter在单个sample输入滑动产生的输出。\n",
    "            W - 在textCNN中，应该就是1\n",
    "        :param x:\n",
    "        :param conv:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # x - (8, 1, 5, 2), 8 - sample, 1 - 编码方式个数， 5 - 句子长度，2 - embedding空间大小\n",
    "        output = conv(x)\n",
    "        # output - (8, 2, 4, 1) 8 - sample, 2 - 每个filter的结果， 4 - 每个filter卷积的结果， 1 - 卷积结果的维度\n",
    "        output = F.relu(output)\n",
    "        # 这里的两个squeeze其实都是为了最后产生一个(sample, filter_num)的shape\n",
    "        output = output.squeeze(3)\n",
    "        # output - (8, 2, 4)\n",
    "        output = F.max_pool1d(output, output.size(2))\n",
    "        # output - (8, 2, 1)，每个filter产生一个4 * 1的结果，在4行里取最大值，代表的是模式抓取的语义\n",
    "        output = output.squeeze(2)\n",
    "        return output\n",
    "\n",
    "\n",
    "def get_embedding_samples(samples, embedding_mapping, sentence_length, embedding_size):\n",
    "    samples_mapping = torch.empty((len(samples), sentence_length, embedding_size))\n",
    "    sample_index = 0\n",
    "    for sample in samples:\n",
    "        cur_sample = []\n",
    "        for index in sample:\n",
    "            index_embedding = embedding_mapping[index]\n",
    "            cur_sample.append(index_embedding)\n",
    "        sample_tensor = torch.from_numpy(np.array(cur_sample))\n",
    "        samples_mapping[sample_index] = sample_tensor\n",
    "        sample_index += 1\n",
    "    return samples_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "用来细致观察CNN的初始化，input，output的含义\n",
    "\"\"\"\n",
    "line_num = 10\n",
    "sentence_maxlen = 5\n",
    "embedding_len = 2\n",
    "args = {\n",
    "    \"class_num\": 2,\n",
    "    \"filter_sizes\": [2, 3, 4],\n",
    "    \"embedding_size\": embedding_len,\n",
    "    \"filter_num\": 2,\n",
    "    \"dropout\": 0.5,\n",
    "\n",
    "}\n",
    "print(\"#0 load movie review data\")\n",
    "textCNN = TextCNN(args)\n",
    "tokenizer, embedding_mapping, X, Y, X_train, X_test, Y_train, Y_test = \\\n",
    "    movie_review_helper.prepare_movie_review_for_task(line_num, sentence_maxlen, embedding_len)\n",
    "X_train_embedding = get_embedding_samples(X_train, embedding_mapping, sentence_maxlen, embedding_len)\n",
    "print(\"#1 calculate net output\")\n",
    "Y_hat = textCNN(X_train_embedding)\n",
    "# Y_hat 应该是(8, 2)\n",
    "print(\"#2 call soft max\")\n",
    "softmax_func = nn.Softmax(dim=1)\n",
    "Y_hat_softmax = softmax_func(Y_hat)\n",
    "print(Y_hat_softmax)\n",
    "print(\"#3 finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "大数据量的用于分类的code\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
