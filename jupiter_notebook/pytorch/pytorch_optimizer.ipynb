{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "对比不同的optimizer\n",
    "看起来Adam又快又好。\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LR = 0.01\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 12\n",
    "\n",
    "# fake dataset\n",
    "x = torch.unsqueeze(torch.linspace(-1, 1, 1000), dim=1)\n",
    "y = x.pow(2) + 0.1*torch.normal(torch.zeros(*x.size()))\n",
    "\n",
    "# plot dataset\n",
    "plt.scatter(x.numpy(), y.numpy())\n",
    "plt.show()\n",
    "\n",
    "# put dateset into torch dataset\n",
    "torch_dataset = Data.TensorDataset(x, y)\n",
    "loader = Data.DataLoader(dataset=torch_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2,)\n",
    "\n",
    "\n",
    "# default network\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(1, 20)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(20, 1)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # different nets\n",
    "    net_SGD         = Net()\n",
    "    net_Momentum    = Net()\n",
    "    net_RMSprop     = Net()\n",
    "    net_Adam        = Net()\n",
    "    nets = [net_SGD, net_Momentum, net_RMSprop, net_Adam]\n",
    "\n",
    "    # different optimizers\n",
    "    opt_SGD         = torch.optim.SGD(net_SGD.parameters(), lr=LR)\n",
    "    opt_Momentum    = torch.optim.SGD(net_Momentum.parameters(), lr=LR, momentum=0.8)\n",
    "    opt_RMSprop     = torch.optim.RMSprop(net_RMSprop.parameters(), lr=LR, alpha=0.9)\n",
    "    opt_Adam        = torch.optim.Adam(net_Adam.parameters(), lr=LR, betas=(0.9, 0.99))\n",
    "    optimizers = [opt_SGD, opt_Momentum, opt_RMSprop, opt_Adam]\n",
    "\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    losses_his = [[], [], [], []]   # record loss\n",
    "\n",
    "    # training\n",
    "    for epoch in range(EPOCH):\n",
    "        print('Epoch: ', epoch)\n",
    "        for step, (b_x, b_y) in enumerate(loader):          # for each training step\n",
    "            for net, opt, l_his in zip(nets, optimizers, losses_his):\n",
    "                output = net(b_x)              # get output for every net\n",
    "                loss = loss_func(output, b_y)  # compute loss for every net\n",
    "                opt.zero_grad()                # clear gradients for next train\n",
    "                loss.backward()                # backpropagation, compute gradients\n",
    "                opt.step()                     # apply gradients\n",
    "                l_his.append(loss.data.numpy())     # loss recoder\n",
    "\n",
    "    labels = ['SGD', 'Momentum', 'RMSprop', 'Adam']\n",
    "    for i, l_his in enumerate(losses_his):\n",
    "        plt.plot(l_his, label=labels[i])\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim((0, 0.2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
