{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "逻辑回归定义\n",
    "分类为1的概率 P(x = 1) = exp{wx} / 1 + exp{wx}，\n",
    "相应的P(x = 0) = 1 / 1 + exp{wx}。\n",
    "\n",
    "令P(x = 1) = f(z) = exp{z} / 1 + exp{z}，其中z = wx，对P(z)求导，\n",
    "可以得到dP/dz = P(z) * (1 - P(z))\n",
    "\n",
    "对于单个sample的损失函数：\n",
    "loss = y * (1 - lnP(z)) + (1 - y) * lnP(z)，\n",
    "当y = 1时，loss = (1 - P(z), 若P(z) -> 1，loss -> 0；若P(z) -> 0，loss -> 无穷大\n",
    "y = 0时，loss = (1 - y) * P(z)，如果若P(z) -> 0，loss -> 0；若P(z) -> 1，loss -> 无穷大\n",
    "\n",
    "loss求导\n",
    "loss对某个w求导，有 d(loss)/d(wi) = (y - f(z))xi (这里需要做loss的导数推导，并利用到上一步的等式)\n",
    "这个推导我依然还是有问题，需要再仔细看看。\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "df_X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df_y = pd.DataFrame(cancer.target, columns=[\"target\"])\n",
    "\n",
    "\"\"\"\n",
    "特征要注意归一化\n",
    "\"\"\"\n",
    "class LogisticRegression(object):\n",
    "    def __init__(self, iteration, feature_num):\n",
    "        self.lr = 0.005\n",
    "        self.max_iteration = iteration\n",
    "        # wx + b\n",
    "        self.w = np.zeros(feature_num + 1)\n",
    "\n",
    "    def train(self, features, labels):\n",
    "        cur_iter = 0\n",
    "        while True:\n",
    "            if cur_iter > self.max_iteration:\n",
    "                break\n",
    "            # 每次拿出一个sample更新\n",
    "            index = random.randint(0, len(labels) - 1)\n",
    "            cur_features = list(features[index])\n",
    "            # 加入bias\n",
    "            cur_features.append(1.0)\n",
    "            y = labels[index]\n",
    "            x = np.array(cur_features)\n",
    "            wx = np.dot(self.w, x)\n",
    "            exp_wx = math.exp(wx)\n",
    "            yhat = exp_wx / (1 + exp_wx)\n",
    "            for i in range(0, len(self.w)):\n",
    "                # 每一个sample可以用来更新所有的w值\n",
    "                \"\"\"\n",
    "                如果y = 1, 而yhat -> 0，即f(z) -> 0，说明预测有误，为了提高预测概率，要提高f(z)的值。\n",
    "                P(x = 1) = exp{wx} / 1 + exp{wx} = 1 - 1 / (1 + exp(wx))，要让P(X = 1)提高，下一轮需要提高wx的值。\n",
    "                如果x[i] > 0，则+号使得w[i]增加了，则下一轮的wx增加，P(x = 1)提高，不论w[x]以前是正负，都是这个结论。\n",
    "                如果x[i] < 0，则+号使得w[i]减小了，w[i]*x[i]减小了，不论w[x]以前是正负，都是这个结论。\n",
    "                综上，+号更新是正确的。同理，可以假设y = 0来推导，应该同样成立。\n",
    "                \"\"\"\n",
    "                self.w[i] += self.lr * (y - yhat) * x[i]\n",
    "            # print(\"iteration - {}\".format(cur_iter))\n",
    "            cur_iter += 1\n",
    "        return\n",
    "\n",
    "    def predict_single(self, x):\n",
    "        try:\n",
    "            wx = np.dot(self.w, x)\n",
    "            exp_wx = math.exp(wx)\n",
    "            predict_1 = exp_wx / (1 + exp_wx)\n",
    "            predict_0 = 1 / (1 + exp_wx)\n",
    "            if predict_1 > predict_0:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        except OverflowError:\n",
    "            print(x)\n",
    "            print(self.w)\n",
    "\n",
    "    def predict_batch(self, features):\n",
    "        labels = []\n",
    "        for feature in features:\n",
    "            cur_features = list(feature)\n",
    "            cur_features.append(1.0)\n",
    "            x = np.array(cur_features)\n",
    "            labels.append(self.predict_single(x))\n",
    "        return labels\n",
    "\n",
    "\n",
    "np_X = df_X.to_numpy()\n",
    "np_y = df_y[\"target\"].to_numpy()\n",
    "scaler = StandardScaler()\n",
    "# np_X_normal = scaler.fit_transform(np_X)\n",
    "# df_np_normal = pd.DataFrame(np_X_normal, columns=cancer.feature_names)\n",
    "# df_np_normal.head(5)\n",
    "np_X = scaler.fit_transform(np_X)\n",
    "\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(np_X, np_y, test_size=0.2, random_state=23323)\n",
    "\n",
    "lr = LogisticRegression(1000, np_X.shape[1])\n",
    "lr.train(train_features, train_labels)\n",
    "predict_labels = lr.predict_batch(test_features)\n",
    "print(predict_labels)\n",
    "print(lr.w)\n",
    "print(accuracy_score(test_labels, predict_labels))\n",
    "\n",
    "lr2 = LogisticRegression(10000, np_X.shape[1])\n",
    "lr2.train(train_features, train_labels)\n",
    "predict_labels2 = lr2.predict_batch(test_features)\n",
    "print(predict_labels2)\n",
    "print(lr2.w)\n",
    "print(accuracy_score(test_labels, predict_labels2))\n",
    "\n",
    "lr3 = LogisticRegression(20000, np_X.shape[1])\n",
    "lr3.train(train_features, train_labels)\n",
    "predict_labels3 = lr3.predict_batch(test_features)\n",
    "print(predict_labels3)\n",
    "print(lr3.w)\n",
    "print(accuracy_score(test_labels, predict_labels3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
