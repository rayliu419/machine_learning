{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/luru/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'alice' and 'wonderland' - CBOW :  0.9993334\n",
      "Cosine similarity between 'alice' and 'machines' - CBOW :  0.98903584\n",
      "Cosine similarity between 'alice' and 'wonderland' - Skip Gram :  0.89565444\n",
      "Cosine similarity between 'alice' and 'machines' - Skip Gram :  0.8621719\n"
     ]
    }
   ],
   "source": [
    "# 使用自己的语料训练word vector。\n",
    "# 在Keras中，可以使用自己训练的vector来作为输入，keras也可以自己训练\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "  \n",
    "import gensim \n",
    "from gensim.models import Word2Vec \n",
    "  \n",
    "#  Reads ‘alice.txt’ file \n",
    "sample = open(\"./input_data/word_embedding.txt\", \"r\") \n",
    "s = sample.read() \n",
    "  \n",
    "# Replaces escape character with space \n",
    "f = s.replace(\"\\n\", \" \") \n",
    "  \n",
    "data = [] \n",
    "  \n",
    "# iterate through each sentence in the file \n",
    "for i in sent_tokenize(f): \n",
    "    temp = [] \n",
    "      \n",
    "    # tokenize the sentence into words \n",
    "    for j in word_tokenize(i): \n",
    "        temp.append(j.lower()) \n",
    "  \n",
    "    data.append(temp) \n",
    "  \n",
    "# Create CBOW model \n",
    "model1 = gensim.models.Word2Vec(data, min_count = 1,  \n",
    "                              size = 100, window = 5) \n",
    "  \n",
    "# Print results \n",
    "print(\"Cosine similarity between 'alice' \" + \n",
    "               \"and 'wonderland' - CBOW : \", \n",
    "    model1.similarity('alice', 'wonderland')) \n",
    "      \n",
    "print(\"Cosine similarity between 'alice' \" +\n",
    "                 \"and 'machines' - CBOW : \", \n",
    "      model1.similarity('alice', 'machines')) \n",
    "  \n",
    "# Create Skip Gram model \n",
    "model2 = gensim.models.Word2Vec(data, min_count = 1, size = 100, \n",
    "                                             window = 5, sg = 1) \n",
    "  \n",
    "# Print results \n",
    "print(\"Cosine similarity between 'alice' \" +\n",
    "          \"and 'wonderland' - Skip Gram : \", \n",
    "    model2.similarity('alice', 'wonderland')) \n",
    "      \n",
    "print(\"Cosine similarity between 'alice' \" +\n",
    "            \"and 'machines' - Skip Gram : \", \n",
    "      model2.similarity('alice', 'machines')) \n",
    "\n",
    "model1.save(\"./output_data/model1.model\")\n",
    "model1.wv.save_word2vec_format(\"./output_data/word_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.43065640e-01,  3.05630594e-01,  1.50814548e-01,  3.06843847e-01,\n",
       "        3.09179146e-02, -2.33413652e-01,  8.33903477e-02,  2.11826175e-01,\n",
       "        1.84128881e-01, -2.42831588e-01,  4.01451796e-01,  1.96025968e-01,\n",
       "        2.41729082e-03, -2.24273831e-01, -7.56566823e-02,  6.10034913e-02,\n",
       "        5.71214199e-01,  6.21969253e-02,  4.14927257e-03,  3.98456305e-02,\n",
       "       -1.88219070e-01,  1.86817363e-01,  3.58706445e-01, -2.41667807e-01,\n",
       "        3.16808343e-01,  5.14114760e-02,  3.41085228e-03, -4.28241998e-01,\n",
       "        4.23554098e-03,  8.01977590e-02,  2.22339466e-01,  1.70453146e-01,\n",
       "       -3.18848789e-02, -7.70290792e-02, -3.04476440e-01, -2.29074121e-01,\n",
       "        2.26375721e-02,  1.36011615e-01,  1.61768630e-01,  1.01708204e-01,\n",
       "        1.30011544e-01,  1.70880184e-01, -1.74531862e-01,  1.90671980e-02,\n",
       "       -1.32148579e-01, -2.68702179e-01, -3.53050739e-01,  1.34526208e-01,\n",
       "        1.29911870e-01,  5.45585275e-01,  6.64830282e-02, -3.14204022e-04,\n",
       "       -1.47975579e-01,  5.27542783e-03, -2.59240210e-01,  2.03419402e-01,\n",
       "       -3.56490761e-02,  6.93063736e-02,  2.96113943e-03, -2.70301461e-01,\n",
       "        1.39972374e-01,  1.82433248e-01, -2.15650201e-01,  2.88944036e-01,\n",
       "       -1.22978389e-01, -5.40646426e-02,  1.12581909e-01, -2.42576785e-02,\n",
       "       -2.69929886e-01, -1.76830903e-01,  2.06131935e-02,  1.05932511e-01,\n",
       "        2.00326711e-01, -7.73143321e-02,  2.25969657e-01, -2.26231769e-01,\n",
       "        5.53700253e-02, -5.65549880e-02,  2.22557098e-01,  4.46690395e-02,\n",
       "        1.14955857e-01, -1.13739006e-01,  4.50616889e-02, -9.76416096e-03,\n",
       "       -9.66306124e-03,  9.94638726e-02, -2.80155450e-01, -4.04682346e-02,\n",
       "       -1.52429909e-01, -1.93183105e-02,  1.67447731e-01,  1.66605115e-01,\n",
       "       -1.12089431e-02, -1.83784544e-01, -2.86432594e-01,  2.30885774e-01,\n",
       "        1.89172462e-01,  4.45984043e-02, -2.49635622e-01,  1.20513305e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2[\"alice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2[\"alice\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
